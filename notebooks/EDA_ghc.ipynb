{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee0fbc4d-679e-4664-b3aa-56af2f719cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nhatminh/venv/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ced80520-0560-49d2-b39b-5b28751d0d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import dask.dataframe as dd\n",
    "from src.utils.utils import get_logger  \n",
    "from dask_ml.model_selection import train_test_split\n",
    "import os\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "042fb3e6-92c6-4577-84cc-de90b76bae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetReader(ABC):\n",
    "    required_columns = {\"text\", \"label\", \"split\", \"dataset_name\"}\n",
    "    split_names = {\"train\", \"dev\", \"test\"}\n",
    "    \n",
    "    def __init__(self, dataset_dir:str, dataset_name:str) -> None:\n",
    "        self.logger = get_logger(self.__class__.__name__)\n",
    "        self.dataset_dir=dataset_dir\n",
    "        self.dataset_name=dataset_name\n",
    "        \n",
    "        \n",
    "    # def read_data(self) -> dd.core.DataFrame:\n",
    "    #     train_df, dev_df, test_df = self._read_data()\n",
    "    #     df = self.assign_split_names_to_data_frames_and_merge(train_df, dev_df, test_df)\n",
    "    #     df[\"dataset_name\"] = self.dataset_name\n",
    "    #     if any(required_column not in df.columns.values for required_column in self.required_columns):\n",
    "    #         raise ValueError(f\"Dataset must contain all required columns: {self.required_columns}\")\n",
    "    #     unique_split_names = set(df[\"split\"].unique().compute().tolist())\n",
    "    #     if unique_split_names != self.split_names:\n",
    "    #         raise ValueError(f\"Dataset must contain all required split names: {self.split_names}\")\n",
    "    #     final_df: dd.core.DataFrame = df[list(self.required_columns)]\n",
    "    #     return final_df\n",
    "    def read_data(self) -> dd.core.DataFrame:\n",
    "        train_df, dev_df, test_df = self._read_data()\n",
    "        df = self.assign_split_names_to_data_frames_and_merge(train_df, dev_df, test_df)\n",
    "        df[\"dataset_name\"] = self.dataset_name\n",
    "        df = df.compute()\n",
    "        if any(required_column not in df.columns.values for required_column in self.required_columns):\n",
    "            raise ValueError(f\"Dataset must contain all required columns: {self.required_columns}\")\n",
    "        unique_split_names = set(df[\"split\"].unique().tolist()) \n",
    "        print(unique_split_names)\n",
    "        if unique_split_names != self.split_names:\n",
    "            raise ValueError(f\"Dataset must contain all required split names: {self.split_names}\")\n",
    "        final_df: dd.core.DataFrame = df[list(self.required_columns)]\n",
    "        return final_df\n",
    "        \n",
    "        \n",
    "    @abstractmethod\n",
    "    def _read_data(self) -> tuple[dd.core.DataFrame, dd.core.DataFrame, dd.core.DataFrame]:\n",
    "        \"\"\"\n",
    "        Read and split dataset into 3 splits: train, dev, test.\n",
    "        The return value must be a dd.core.DataFrame, with required columns: self.required_columns\n",
    "        \"\"\"\n",
    "        \n",
    "    def assign_split_names_to_data_frames_and_merge(self, train_df:dd.core.DataFrame, dev_df: dd.core.DataFrame, test_df:dd.core.DataFrame) -> dd.core.DataFrame:\n",
    "       train_df[\"split\"] = \"train\"\n",
    "       dev_df[\"split\"] = \"dev\"\n",
    "       test_df[\"split\"] = \"test\"\n",
    "       return dd.concat([train_df, dev_df, test_df])\n",
    "        \n",
    "        \n",
    "    def split_dataset(\n",
    "        self, df: dd.core.DataFrame, test_size: float, stratify_column: Optional[str] = None\n",
    "    ) -> tuple[dd.core.DataFrame, dd.core.DataFrame]:\n",
    "        if stratify_column is None:\n",
    "            return train_test_split(df, test_size=test_size, random_state=1234, shuffle=True)  # type: ignore\n",
    "        unique_column_values = df[stratify_column].unique()\n",
    "        first_dfs = []\n",
    "        second_dfs = []\n",
    "        for unique_set_value in unique_column_values:\n",
    "            sub_df = df[df[stratify_column] == unique_set_value]\n",
    "            sub_first_df, sub_second_df = train_test_split(sub_df, test_size=test_size, random_state=1234, shuffle=True)\n",
    "            first_dfs.append(sub_first_df)\n",
    "            second_dfs.append(sub_second_df)\n",
    "\n",
    "        first_df = dd.concat(first_dfs)  # type: ignore\n",
    "        second_df = dd.concat(second_dfs)  # type: ignore\n",
    "        return first_df, second_df\n",
    "\n",
    "    # def get_remote_data_url(self, dataset_path: str) -> str:\n",
    "    #     dataset_url: str = get_url(path=dataset_path, repo=self.dvc_remote_repo, rev=self.version)\n",
    "    #     return dataset_url\n",
    "        \n",
    "        \n",
    "class GHCDatasetReader(DatasetReader):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_dir: str,\n",
    "        dataset_name: str,\n",
    "        dev_split_ratio: float,\n",
    "        # gcp_project_id: str,\n",
    "        # gcp_github_access_token_secret_id: str,\n",
    "        # dvc_remote_repo: str,\n",
    "        # github_user_name: str,\n",
    "        # version: str,\n",
    "    ) -> None:\n",
    "        super().__init__(\n",
    "            dataset_dir,\n",
    "            dataset_name,\n",
    "            # gcp_project_id,\n",
    "            # gcp_github_access_token_secret_id,\n",
    "            # dvc_remote_repo,\n",
    "            # github_user_name,\n",
    "            # version,\n",
    "        )\n",
    "        self.dev_split_ratio = dev_split_ratio\n",
    "\n",
    "    def _read_data(self) -> tuple[dd.core.DataFrame, dd.core.DataFrame, dd.core.DataFrame]:\n",
    "        self.logger.info(\"Reading GHC dataset...\")\n",
    "        train_tsv_path = os.path.join(self.dataset_dir, \"ghc_train.tsv\")\n",
    "        # train_tsv_url = self.get_remote_data_url(train_tsv_path)\n",
    "        # train_df = dd.read_csv(train_tsv_url, sep=\"\\t\", header=0)\n",
    "        train_df = dd.read_csv(train_tsv_path, sep=\"\\t\", header=0)\n",
    "\n",
    "        test_tsv_path = os.path.join(self.dataset_dir, \"ghc_test.tsv\")\n",
    "        test_df = dd.read_csv(test_tsv_path, sep=\"\\t\", header=0)\n",
    "        # test_tsv_url = self.get_remote_data_url(test_tsv_path)\n",
    "        # test_df = dd.read_csv(test_tsv_url, sep=\"\\t\", header=0)\n",
    "        \n",
    "        train_df[\"label\"] = (train_df[\"hd\"] + train_df[\"cv\"] + train_df[\"vo\"] > 0).astype(int)\n",
    "        test_df[\"label\"] = (test_df[\"hd\"] + test_df[\"cv\"] + test_df[\"vo\"] > 0).astype(int)\n",
    "\n",
    "        train_df, dev_df = self.split_dataset(train_df, self.dev_split_ratio, stratify_column=\"label\")\n",
    "\n",
    "        return train_df, dev_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1f13a2da-8194-4755-abb9-d0e88144b02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_reader = GHCDatasetReader(dataset_dir= \"./data/raw/ghc\", dataset_name=\"ghc\", dev_split_ratio= 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "88c0e042-c3db-4cf9-b94c-c24fff2a9159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test', 'dev', 'train'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>text</th>\n",
       "      <th>split</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13501</th>\n",
       "      <td>ghc</td>\n",
       "      <td>Boris Johnson has written another storming art...</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14241</th>\n",
       "      <td>ghc</td>\n",
       "      <td>@Tripper</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>ghc</td>\n",
       "      <td>Who changed the truth of God into a lie, and w...</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>ghc</td>\n",
       "      <td>Thanks Ken! And thanks always for your photogr...</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15944</th>\n",
       "      <td>ghc</td>\n",
       "      <td>First cousin marriages do not always produce g...</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5505</th>\n",
       "      <td>ghc</td>\n",
       "      <td>Trump To \"Counter\" DNC Lawsuit; Seeks Servers,...</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5506</th>\n",
       "      <td>ghc</td>\n",
       "      <td>i guess eu is gonna have to back track a littl...</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5507</th>\n",
       "      <td>ghc</td>\n",
       "      <td>A good read here....    https://countrysquire....</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5508</th>\n",
       "      <td>ghc</td>\n",
       "      <td>The only way to change things is to have compa...</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5509</th>\n",
       "      <td>ghc</td>\n",
       "      <td>And Tel Aviv, Jerusalem, New York, LA, Berlin,...</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27546 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset_name                                               text  split  \\\n",
       "13501          ghc  Boris Johnson has written another storming art...  train   \n",
       "14241          ghc                                         @Tripper    train   \n",
       "542            ghc  Who changed the truth of God into a lie, and w...  train   \n",
       "2001           ghc  Thanks Ken! And thanks always for your photogr...  train   \n",
       "15944          ghc  First cousin marriages do not always produce g...  train   \n",
       "...            ...                                                ...    ...   \n",
       "5505           ghc  Trump To \"Counter\" DNC Lawsuit; Seeks Servers,...   test   \n",
       "5506           ghc  i guess eu is gonna have to back track a littl...   test   \n",
       "5507           ghc  A good read here....    https://countrysquire....   test   \n",
       "5508           ghc  The only way to change things is to have compa...   test   \n",
       "5509           ghc  And Tel Aviv, Jerusalem, New York, LA, Berlin,...   test   \n",
       "\n",
       "       label  \n",
       "13501      0  \n",
       "14241      0  \n",
       "542        0  \n",
       "2001       0  \n",
       "15944      0  \n",
       "...      ...  \n",
       "5505       0  \n",
       "5506       0  \n",
       "5507       0  \n",
       "5508       0  \n",
       "5509       0  \n",
       "\n",
       "[27546 rows x 4 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_reader.read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ad97c2cc-5f79-4a65-b43a-3214d3f7ca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, dev_df, test_df = dataset_reader._read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c598d74-a071-4b5b-a10f-907c5f05aaab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17676"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfc8fc5c-d443-4573-992a-6f0ae2a0b2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4360"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fa11631-63ba-440c-86db-53813c1c1937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5510"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c4ca461-b314-4a2c-a311-62b63b25fa1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hd</th>\n",
       "      <th>cv</th>\n",
       "      <th>vo</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13501</th>\n",
       "      <td>Boris Johnson has written another storming art...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14241</th>\n",
       "      <td>@Tripper</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>Who changed the truth of God into a lie, and w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>Thanks Ken! And thanks always for your photogr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15944</th>\n",
       "      <td>First cousin marriages do not always produce g...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  hd  cv  vo  label  \\\n",
       "13501  Boris Johnson has written another storming art...   0   0   0      0   \n",
       "14241                                         @Tripper     0   0   0      0   \n",
       "542    Who changed the truth of God into a lie, and w...   0   0   0      0   \n",
       "2001   Thanks Ken! And thanks always for your photogr...   0   0   0      0   \n",
       "15944  First cousin marriages do not always produce g...   0   0   0      0   \n",
       "\n",
       "       split  \n",
       "13501  train  \n",
       "14241  train  \n",
       "542    train  \n",
       "2001   train  \n",
       "15944  train  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset_reader.assign_split_names_to_data_frames_and_merge(train_df, dev_df, test_df)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ce1399b-c7bb-49bc-9814-57149016ed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dd.read_csv(\"./data/raw/ghc/ghc_train.tsv\", sep=\"\\t\", header=0)\n",
    "test_df = dd.read_csv(\"./data/raw/ghc/ghc_test.tsv\", sep=\"\\t\", header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3df93e8c-787c-4c31-98b5-4f2dadb2cdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df.shape=(<dask_expr.expr.Scalar: expr=ReadCSV(28dabe4).size() // 4, dtype=int64>, 4)\n",
      "test_df.shape=(<dask_expr.expr.Scalar: expr=ReadCSV(79b189f).size() // 4, dtype=int64>, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{train_df.shape=}\")\n",
    "print(f\"{test_df.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49f7511b-3207-4d17-a572-d3881c782240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hd</th>\n",
       "      <th>cv</th>\n",
       "      <th>vo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He most likely converted to islam due to his n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So Ford lied about being a psychologist. Recor...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jobs. Education. Ending abuse of Nation. CA43.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I share a lot of your values, &amp; like many who ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am so ready to get back to blogging! www.ben...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>taking a look at new opportunity called FX Pro...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Reflecting back when I was in school with Spec...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Let's be honest everyone, last year there were...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2007 Nuke plant in Syria</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NBC's Chuck Todd Thinks He's Figured It All Ou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  hd  cv  vo\n",
       "0  He most likely converted to islam due to his n...   0   0   0\n",
       "1  So Ford lied about being a psychologist. Recor...   0   0   0\n",
       "2     Jobs. Education. Ending abuse of Nation. CA43.   0   0   0\n",
       "3  I share a lot of your values, & like many who ...   0   0   0\n",
       "4  I am so ready to get back to blogging! www.ben...   0   0   0\n",
       "5  taking a look at new opportunity called FX Pro...   0   0   0\n",
       "6  Reflecting back when I was in school with Spec...   0   0   0\n",
       "7  Let's be honest everyone, last year there were...   0   0   0\n",
       "8                          2007 Nuke plant in Syria    0   0   0\n",
       "9  NBC's Chuck Todd Thinks He's Figured It All Ou...   0   0   0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "199f2cc4-6b55-46fe-8f09-aa1ad7522f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hd</th>\n",
       "      <th>cv</th>\n",
       "      <th>vo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.youtube.com/watch?v=kACWpKAKtak A ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Very nice! I tend to get tired of the constant...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Watch today. https://circumcisionmovie.com/</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" Thinking Venues \" First Color Layer blocking...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What about death penalty for perpetrators  and...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>You have insecurities? Fuck you</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Powerful Truths About Donald Trump the Media D...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Just saw an Oreo cookie commercial. Drool.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I bet a neural net with half a dozen nodes co...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Country by country, the 'Prague Spring' that w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  hd  cv  vo\n",
       "0  https://www.youtube.com/watch?v=kACWpKAKtak A ...   0   0   0\n",
       "1  Very nice! I tend to get tired of the constant...   0   0   0\n",
       "2        Watch today. https://circumcisionmovie.com/   0   0   0\n",
       "3  \" Thinking Venues \" First Color Layer blocking...   0   0   0\n",
       "4  What about death penalty for perpetrators  and...   0   0   0\n",
       "5                   You have insecurities? Fuck you    0   0   0\n",
       "6  Powerful Truths About Donald Trump the Media D...   0   0   0\n",
       "7         Just saw an Oreo cookie commercial. Drool.   0   0   0\n",
       "8   I bet a neural net with half a dozen nodes co...   0   0   0\n",
       "9  Country by country, the 'Prague Spring' that w...   0   0   0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab90b03-aebc-4597-8537-a5ece651b645",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
